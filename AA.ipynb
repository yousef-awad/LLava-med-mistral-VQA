{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4919b425",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef739276",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:38:27.895271Z",
     "iopub.status.busy": "2025-12-29T23:38:27.895271Z",
     "iopub.status.idle": "2025-12-29T23:38:31.074342Z",
     "shell.execute_reply": "2025-12-29T23:38:31.074342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import warnings\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from PIL import Image\n",
    "from collections import defaultdict, Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d421ebf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:38:31.074342Z",
     "iopub.status.busy": "2025-12-29T23:38:31.074342Z",
     "iopub.status.idle": "2025-12-29T23:38:31.079934Z",
     "shell.execute_reply": "2025-12-29T23:38:31.079934Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 777\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99397a91",
   "metadata": {},
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5371e71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:38:31.079934Z",
     "iopub.status.busy": "2025-12-29T23:38:31.079934Z",
     "iopub.status.idle": "2025-12-29T23:38:31.090688Z",
     "shell.execute_reply": "2025-12-29T23:38:31.090688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2248"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_DIR = \"VQA_RAD/VQA_RAD Image Folder\"\n",
    "JSON_PATH = \"VQA_RAD/VQA_RAD Dataset Public.json\"\n",
    "\n",
    "with open(JSON_PATH, \"r\") as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9be8bc6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:38:31.090688Z",
     "iopub.status.busy": "2025-12-29T23:38:31.090688Z",
     "iopub.status.idle": "2025-12-29T23:38:31.093664Z",
     "shell.execute_reply": "2025-12-29T23:38:31.093664Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_answer(ans):\n",
    "    ans = ans.lower().strip()\n",
    "    if ans in [\"yes\", \"y\"]:\n",
    "        return 1\n",
    "    if ans in [\"no\", \"n\"]:\n",
    "        return 0\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d2cc349",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:38:31.093664Z",
     "iopub.status.busy": "2025-12-29T23:38:31.093664Z",
     "iopub.status.idle": "2025-12-29T23:38:31.098432Z",
     "shell.execute_reply": "2025-12-29T23:38:31.098432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "477"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = []\n",
    "\n",
    "for item in raw_data:\n",
    "    if item.get(\"image_organ\", \"\").lower() != \"chest\":\n",
    "        continue\n",
    "\n",
    "    if item.get(\"answer_type\", \"\").lower() != \"closed\":\n",
    "        continue\n",
    "\n",
    "    label = normalize_answer(item.get(\"answer\", \"\"))\n",
    "    if label is None:\n",
    "        continue\n",
    "\n",
    "    image_name = item.get(\"image_name\")\n",
    "    if image_name is None:\n",
    "        continue\n",
    "\n",
    "    samples.append({\n",
    "        \"image_path\": os.path.join(IMAGE_DIR, image_name),  # synpicXXXX.jpg\n",
    "        \"image_id\": image_name,\n",
    "        \"question\": item[\"question\"].lower(),\n",
    "        \"label\": label\n",
    "    })\n",
    "\n",
    "len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56248c9c",
   "metadata": {},
   "source": [
    "### Image-level Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91672895",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:38:31.099363Z",
     "iopub.status.busy": "2025-12-29T23:38:31.099363Z",
     "iopub.status.idle": "2025-12-29T23:38:31.102909Z",
     "shell.execute_reply": "2025-12-29T23:38:31.102909Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 49, 63)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def image_level_split(samples, seed=SEED):\n",
    "    random.seed(seed)\n",
    "\n",
    "    image_to_samples = defaultdict(list)\n",
    "    for s in samples:\n",
    "        image_to_samples[s[\"image_id\"]].append(s)\n",
    "\n",
    "    image_ids = list(image_to_samples.keys())\n",
    "    random.shuffle(image_ids)\n",
    "\n",
    "    n = len(image_ids)\n",
    "    train_ids = image_ids[:int(0.8 * n)]\n",
    "    val_ids   = image_ids[int(0.8 * n):int(0.9 * n)]\n",
    "    test_ids  = image_ids[int(0.9 * n):]\n",
    "\n",
    "    def collect(ids):\n",
    "        out = []\n",
    "        for i in ids:\n",
    "            out.extend(image_to_samples[i])\n",
    "        return out\n",
    "\n",
    "    return collect(train_ids), collect(val_ids), collect(test_ids)\n",
    "\n",
    "train_samples, val_samples, test_samples = image_level_split(samples)\n",
    "len(train_samples), len(val_samples), len(test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c63d33",
   "metadata": {},
   "source": [
    "### Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53b15e16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:38:31.102909Z",
     "iopub.status.busy": "2025-12-29T23:38:31.102909Z",
     "iopub.status.idle": "2025-12-29T23:38:31.106402Z",
     "shell.execute_reply": "2025-12-29T23:38:31.106402Z"
    }
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084ffba9",
   "metadata": {},
   "source": [
    "### Vocabulary + Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a43f1cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:38:31.107571Z",
     "iopub.status.busy": "2025-12-29T23:38:31.107571Z",
     "iopub.status.idle": "2025-12-29T23:38:31.109387Z",
     "shell.execute_reply": "2025-12-29T23:38:31.109387Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text.lower())\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03aa4552",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:38:31.110009Z",
     "iopub.status.busy": "2025-12-29T23:38:31.110009Z",
     "iopub.status.idle": "2025-12-29T23:38:31.114227Z",
     "shell.execute_reply": "2025-12-29T23:38:31.114227Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter = Counter()\n",
    "for s in train_samples:\n",
    "    word_counter.update(tokenize(s[\"question\"]))\n",
    "\n",
    "vocab = {\"<pad>\": 0, \"<unk>\": 1}\n",
    "for w in word_counter:\n",
    "    vocab[w] = len(vocab)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d8ee2d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:38:31.114227Z",
     "iopub.status.busy": "2025-12-29T23:38:31.114227Z",
     "iopub.status.idle": "2025-12-29T23:38:31.117767Z",
     "shell.execute_reply": "2025-12-29T23:38:31.117767Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_question(q, vocab, max_len=30):\n",
    "    tokens = tokenize(q)\n",
    "    ids = [vocab.get(t, vocab[\"<unk>\"]) for t in tokens][:max_len]\n",
    "    return ids + [0] * (max_len - len(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1c0667",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b53a96c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:38:31.117767Z",
     "iopub.status.busy": "2025-12-29T23:38:31.117767Z",
     "iopub.status.idle": "2025-12-29T23:38:31.121402Z",
     "shell.execute_reply": "2025-12-29T23:38:31.121402Z"
    }
   },
   "outputs": [],
   "source": [
    "class VQARadMultimodalDataset(Dataset):\n",
    "    def __init__(self, samples, transform, vocab):\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s = self.samples[idx]\n",
    "        image = Image.open(s[\"image_path\"]).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "\n",
    "        question = torch.tensor(\n",
    "            encode_question(s[\"question\"], self.vocab),\n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        label = torch.tensor(s[\"label\"], dtype=torch.long)\n",
    "        return image, question, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2382563",
   "metadata": {},
   "source": [
    "### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30f95fe4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:38:31.121402Z",
     "iopub.status.busy": "2025-12-29T23:38:31.121402Z",
     "iopub.status.idle": "2025-12-29T23:38:31.124875Z",
     "shell.execute_reply": "2025-12-29T23:38:31.124875Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    VQARadMultimodalDataset(train_samples, train_transform, vocab),\n",
    "    batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    VQARadMultimodalDataset(val_samples, eval_transform, vocab),\n",
    "    batch_size=BATCH_SIZE, shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    VQARadMultimodalDataset(test_samples, eval_transform, vocab),\n",
    "    batch_size=BATCH_SIZE, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e37871",
   "metadata": {},
   "source": [
    "### Model + Freeze Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83e576a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:38:31.124875Z",
     "iopub.status.busy": "2025-12-29T23:38:31.124875Z",
     "iopub.status.idle": "2025-12-29T23:38:31.128743Z",
     "shell.execute_reply": "2025-12-29T23:38:31.128743Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResNetBiLSTMVQA(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=300, lstm_hidden=128, dropout=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = models.resnet50(pretrained=True)\n",
    "        cnn_dim = self.cnn.fc.in_features\n",
    "        self.cnn.fc = nn.Identity()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, lstm_hidden, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(cnn_dim + 2*lstm_hidden, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, question):\n",
    "        img_feat = self.cnn(image)\n",
    "        emb = self.embedding(question)\n",
    "        _, (h, _) = self.lstm(emb)\n",
    "        q_feat = torch.cat([h[-2], h[-1]], dim=1)\n",
    "        return self.classifier(torch.cat([img_feat, q_feat], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08c1034f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:38:31.128743Z",
     "iopub.status.busy": "2025-12-29T23:38:31.128743Z",
     "iopub.status.idle": "2025-12-29T23:38:31.132098Z",
     "shell.execute_reply": "2025-12-29T23:38:31.132098Z"
    }
   },
   "outputs": [],
   "source": [
    "def freeze_cnn(model):\n",
    "    for p in model.cnn.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "def unfreeze_cnn(model):\n",
    "    for p in model.cnn.parameters():\n",
    "        p.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69588b6b",
   "metadata": {},
   "source": [
    "### Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce49d897",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:38:31.132098Z",
     "iopub.status.busy": "2025-12-29T23:38:31.132098Z",
     "iopub.status.idle": "2025-12-29T23:38:31.135652Z",
     "shell.execute_reply": "2025-12-29T23:38:31.135652Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_epoch(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    for img, q, y in loader:\n",
    "        img, q, y = img.to(device), q.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(img, q), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total += loss.item()\n",
    "    return total / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c26e444b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:38:31.135652Z",
     "iopub.status.busy": "2025-12-29T23:38:31.135652Z",
     "iopub.status.idle": "2025-12-29T23:38:31.139223Z",
     "shell.execute_reply": "2025-12-29T23:38:31.139223Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    for img, q, y in loader:\n",
    "        img, q = img.to(device), q.to(device)\n",
    "        p = model(img, q).argmax(1)\n",
    "        preds.extend(p.cpu().numpy())\n",
    "        labels.extend(y.numpy())\n",
    "    return accuracy_score(labels, preds), f1_score(labels, preds, average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cd9c6f",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bbc303d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:38:31.139223Z",
     "iopub.status.busy": "2025-12-29T23:38:31.139223Z",
     "iopub.status.idle": "2025-12-29T23:38:31.142116Z",
     "shell.execute_reply": "2025-12-29T23:38:31.142116Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\"embed_dim\": 300, \"lstm_hidden\": 128, \"dropout\": 0.3, \"lr\": 1e-4},\n",
    "    {\"embed_dim\": 300, \"lstm_hidden\": 128, \"dropout\": 0.5, \"lr\": 5e-5},\n",
    "    {\"embed_dim\": 100, \"lstm_hidden\": 64,  \"dropout\": 0.3, \"lr\": 1e-4},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da618202",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:38:31.142116Z",
     "iopub.status.busy": "2025-12-29T23:38:31.142116Z",
     "iopub.status.idle": "2025-12-29T23:38:31.145804Z",
     "shell.execute_reply": "2025-12-29T23:38:31.145498Z"
    }
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def step(self, score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "519617da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:38:31.145804Z",
     "iopub.status.busy": "2025-12-29T23:38:31.145804Z",
     "iopub.status.idle": "2025-12-29T23:38:31.149935Z",
     "shell.execute_reply": "2025-12-29T23:38:31.149935Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_experiment(params):\n",
    "    model = ResNetBiLSTMVQA(\n",
    "        vocab_size,\n",
    "        embed_dim=params[\"embed_dim\"],\n",
    "        lstm_hidden=params[\"lstm_hidden\"],\n",
    "        dropout=params[\"dropout\"]\n",
    "    ).to(device)\n",
    "\n",
    "    freeze_cnn(model)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=params[\"lr\"],\n",
    "        weight_decay=1e-4\n",
    "    )\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode=\"max\", patience=2, factor=0.5\n",
    "    )\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=3)\n",
    "    best_val_f1 = 0.0\n",
    "\n",
    "    for epoch in range(20):\n",
    "        if epoch == 5:\n",
    "            unfreeze_cnn(model)\n",
    "            optimizer = torch.optim.AdamW(\n",
    "                model.parameters(),\n",
    "                lr=optimizer.param_groups[0][\"lr\"],\n",
    "                weight_decay=1e-4\n",
    "            )\n",
    "\n",
    "        train_epoch(model, train_loader, optimizer)\n",
    "        val_acc, val_f1 = evaluate(model, val_loader)\n",
    "\n",
    "        scheduler.step(val_f1)\n",
    "        best_val_f1 = max(best_val_f1, val_f1)\n",
    "\n",
    "        early_stopping.step(val_f1)\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "\n",
    "    return best_val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecab74f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:38:31.150945Z",
     "iopub.status.busy": "2025-12-29T23:38:31.150945Z",
     "iopub.status.idle": "2025-12-29T23:40:44.599638Z",
     "shell.execute_reply": "2025-12-29T23:40:44.599638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: {'embed_dim': 300, 'lstm_hidden': 128, 'dropout': 0.3, 'lr': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: {'embed_dim': 300, 'lstm_hidden': 128, 'dropout': 0.5, 'lr': 5e-05}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: {'embed_dim': 100, 'lstm_hidden': 64, 'dropout': 0.3, 'lr': 0.0001}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'embed_dim': 300,\n",
       "  'lstm_hidden': 128,\n",
       "  'dropout': 0.3,\n",
       "  'lr': 0.0001,\n",
       "  'val_f1': 0.5811965811965812},\n",
       " {'embed_dim': 300,\n",
       "  'lstm_hidden': 128,\n",
       "  'dropout': 0.5,\n",
       "  'lr': 5e-05,\n",
       "  'val_f1': 0.4555555555555556},\n",
       " {'embed_dim': 100,\n",
       "  'lstm_hidden': 64,\n",
       "  'dropout': 0.3,\n",
       "  'lr': 0.0001,\n",
       "  'val_f1': 0.6165884194053208}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for p in param_grid:\n",
    "    print(\"Testing:\", p)\n",
    "    f1 = run_experiment(p)\n",
    "    results.append({**p, \"val_f1\": f1})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5c3299",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "274addd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:40:44.601053Z",
     "iopub.status.busy": "2025-12-29T23:40:44.599638Z",
     "iopub.status.idle": "2025-12-29T23:40:44.836544Z",
     "shell.execute_reply": "2025-12-29T23:40:44.836544Z"
    }
   },
   "outputs": [],
   "source": [
    "BEST_MODEL = {\n",
    "    \"embed_dim\": 300,\n",
    "    \"lstm_hidden\": 128,\n",
    "    \"dropout\": 0.3\n",
    "}\n",
    "\n",
    "BEST_LR = 1e-4\n",
    "\n",
    "model = ResNetBiLSTMVQA(vocab_size, **BEST_MODEL).to(device)\n",
    "freeze_cnn(model)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=BEST_LR,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"max\", patience=3, factor=0.5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "909e1ede",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:40:44.836544Z",
     "iopub.status.busy": "2025-12-29T23:40:44.836544Z",
     "iopub.status.idle": "2025-12-29T23:41:19.677686Z",
     "shell.execute_reply": "2025-12-29T23:41:19.677686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 0.6885 | Val Acc: 0.6939 | Val Macro-F1: 0.5455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Train Loss: 0.6815 | Val Acc: 0.7143 | Val Macro-F1: 0.4167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Train Loss: 0.6617 | Val Acc: 0.7143 | Val Macro-F1: 0.4167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Train Loss: 0.6636 | Val Acc: 0.7143 | Val Macro-F1: 0.4167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Train Loss: 0.6419 | Val Acc: 0.7143 | Val Macro-F1: 0.4167\n",
      "Unfreezing CNN backbone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Train Loss: 0.6424 | Val Acc: 0.7143 | Val Macro-F1: 0.4167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Train Loss: 0.5303 | Val Acc: 0.7143 | Val Macro-F1: 0.4167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Train Loss: 0.4842 | Val Acc: 0.7143 | Val Macro-F1: 0.4167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Train Loss: 0.4613 | Val Acc: 0.7143 | Val Macro-F1: 0.4167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.4428 | Val Acc: 0.5714 | Val Macro-F1: 0.4035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.4663 | Val Acc: 0.6531 | Val Macro-F1: 0.4450\n",
      "Early stopping triggered at epoch 11\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience=10)\n",
    "best_val_f1 = 0.0\n",
    "\n",
    "for epoch in range(30):\n",
    "\n",
    "    if epoch == 5:\n",
    "        print(\"Unfreezing CNN backbone\")\n",
    "        unfreeze_cnn(model)\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=optimizer.param_groups[0][\"lr\"],\n",
    "            weight_decay=1e-4\n",
    "        )\n",
    "\n",
    "    train_loss = train_epoch(model, train_loader, optimizer)\n",
    "    val_acc, val_f1 = evaluate(model, val_loader)\n",
    "\n",
    "    scheduler.step(val_f1)\n",
    "\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        torch.save(model.state_dict(), \"best_resnet_bilstm_vqa.pt\")\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1:02d} | \"\n",
    "        f\"Train Loss: {train_loss:.4f} | \"\n",
    "        f\"Val Acc: {val_acc:.4f} | \"\n",
    "        f\"Val Macro-F1: {val_f1:.4f}\"\n",
    "    )\n",
    "\n",
    "    early_stopping.step(val_f1)\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d650e4d6",
   "metadata": {},
   "source": [
    "### Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "125214ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:41:19.678560Z",
     "iopub.status.busy": "2025-12-29T23:41:19.678560Z",
     "iopub.status.idle": "2025-12-29T23:41:20.040858Z",
     "shell.execute_reply": "2025-12-29T23:41:20.040858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.5555555555555556\n",
      "Test F1: 0.5288461538461539\n"
     ]
    }
   ],
   "source": [
    "test_acc, test_f1 = evaluate(model, test_loader)\n",
    "print(\"Test Acc:\", test_acc)\n",
    "print(\"Test F1:\", test_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
